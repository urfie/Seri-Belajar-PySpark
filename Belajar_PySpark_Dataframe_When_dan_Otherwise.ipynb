{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Belajar PySpark - Dataframe when dan otherwise"
      ],
      "metadata": {
        "id": "UM2JiIyQj-30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada artikel sebelumnya sudah dibahas tentang filter pyspark DataFrame dengan fungsi withColumn, maka kali ini kita akan belajar mengenai penggunaan fungsi when dan otherwise.\n",
        "\n",
        "Fungsi when dan otherwise digunakan untuk memilih sebuah nilai dengan melakukan pengecekan beberapa kondisi secara bertahap. Fungsi ini serupa dengan ekspresi CASE WHEN dalam perintah SQL. Penerapannya yang paling sering adalah untuk menambahkan kolom baru berdasarkan nilai kolom-kolom lain yang sudah ada.\n",
        "\n",
        "Sintaks rangkaian when-otherwise adalah sebagai berikut :\n",
        "\n",
        "`F.when(kondisi_1, output_1)`\n",
        "<br>&emsp;&emsp;&emsp;`.when(kondisi_2, output_2)`\n",
        "<br>&emsp;&emsp;&emsp;`…`\n",
        "<br>&emsp;&emsp;&emsp;`.when(kondisi_N, output_N)`\n",
        "<br>&emsp;&emsp;&emsp;`.otherwise(output_default))`"
      ],
      "metadata": {
        "id": "SsnT6ThekDeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perhatikan bahwa dalam rangkain kode di atas kita memanggil 2 jenis fungsi `when()` yang berbeda.\n",
        "\n",
        "1. Fungsi when pertama adalah fungsi dari package `pyspark.sql.functions` Pada contoh di atas kita memanggilnya dengan `F.when()` karena kita melakukan import `pyspark.sql.functions` sebagai F dengan perintah `pyspark.sql.functions as F`\n",
        "2. Fungsi when kedua dan seterusnya adalah fungsi dari object `pyspark.sql.Column`.\n",
        "\n",
        "Meskipun demikian, kedua fungsi tersebut melakukan hal yang sama, yaitu menerima parameter berupa kondisi, dan mengembalikan object bertipe Column.\n",
        "\n",
        "Pada artikel ini kita akan membahas 3 cara menambahkan kolom baru di Spark DataFrame berdasar kolom yang sudah ada, yaitu :\n",
        "\n",
        "1. Menggunakan withColumn dan when-otherwise\n",
        "2. Menggunakan select dan when-otherwise\n",
        "2. Menggunakan select dan when-otherwise untuk menambahkan beberapa kolom sekaligus\n",
        "\n",
        "Pertama-tama kita install package pyspark.\n"
      ],
      "metadata": {
        "id": "o_Dj5qiXlHxf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ_Y6tPZZMWe",
        "outputId": "bda14c3d-a95b-4dd8-a7db-abfe7ac7ecdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285397 sha256=658dd9cc9f76106b7f2190812d188752f276d0b00cd6bcac67347d15426a3867\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah package yang akan kita gunakan dalam artikel ini:"
      ],
      "metadata": {
        "id": "uBjEi_U0lfeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F"
      ],
      "metadata": {
        "id": "lPA2PIwKZNDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya kita buat object SparkSession dengan nama aplikasi *‘Belajar Pyspark - When Otherwise’*.\n"
      ],
      "metadata": {
        "id": "6Bey3RvXlgdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Belajar PySpark - When Otherwise').getOrCreate()"
      ],
      "metadata": {
        "id": "Vdcfi7v6ZOjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataFrame yang akan kita gunakan adalah sebagai berikut:"
      ],
      "metadata": {
        "id": "IaMHz046ltJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [['Agus','Fisika',100],['Windy','Fisika',200],\n",
        "        ['Budi','Biologi',200],['Dina','Fisika',140],\n",
        "        ['Bayu','Fisika',50],['Dedi','Biologi',50]]\n",
        "\n",
        "kolom = ['nama','jurusan','nilai']\n",
        "\n",
        "df = spark.createDataFrame(data,kolom)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH_Y46h1ZTeM",
        "outputId": "9984c730-cd96-4509-f0e3-4e4157662ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+\n",
            "| nama|jurusan|nilai|\n",
            "+-----+-------+-----+\n",
            "| Agus| Fisika|  100|\n",
            "|Windy| Fisika|  200|\n",
            "| Budi|Biologi|  200|\n",
            "| Dina| Fisika|  140|\n",
            "| Bayu| Fisika|   50|\n",
            "| Dedi|Biologi|   50|\n",
            "+-----+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kita akan menambahkan satu kolom bernama 'level', berdasar kolom 'nilai', dengan aturan:\n",
        "- Jika nilai kurang dari 100 maka level = ‘Low’.\n",
        "- Jika nilai antara 100 sampai kurang dari 150 maka level = ‘Medium’.\n",
        "- Jika nilai 150 ke atas maka level = ‘High’.\n"
      ],
      "metadata": {
        "id": "1oyyQm_jDs5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##withColumn dan when-otherwise pada DataFrame"
      ],
      "metadata": {
        "id": "WmX62cs6lzFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cara pertama adalah kita menggunakan fungsi `withColumn()` yang digabungkan dengan fungsi-fungsi `when()` dan `otherwise()`.\n",
        "\n",
        "Sintaks withColumn dengan when-otherwise adalah :\n",
        "\n",
        "`df.withColumn(nama_kolom, ekspresi-when-otherwise)`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lN7bmw-0l2vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"level\", F.when(df.nilai < 100,\"Low\")\n",
        "                                 .when(df.nilai < 150,\"Medium\")\n",
        "                                 .otherwise(\"High\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duO1DXCxj-7R",
        "outputId": "fdb62a22-2253-41c8-8295-a407aafed3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+------+\n",
            "| nama|jurusan|nilai| level|\n",
            "+-----+-------+-----+------+\n",
            "| Agus| Fisika|  100|Medium|\n",
            "|Windy| Fisika|  200|  High|\n",
            "| Budi|Biologi|  200|  High|\n",
            "| Dina| Fisika|  140|Medium|\n",
            "| Bayu| Fisika|   50|   Low|\n",
            "| Dedi|Biologi|   50|   Low|\n",
            "+-----+-------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##select dan when-otherwise pada DataFrame"
      ],
      "metadata": {
        "id": "Z_351sKOmCwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selain menggunakan `withColumn()`, kita bisa juga menggunakan fungsi `select()` untuk mengembalikan kolom-kolom tertentu.\n",
        "\n",
        "Sintaksnya adalah sebagai berikut\n",
        "\n",
        "`df.select(list_kolom, ekspresi-when-otherwise.alias(nama_kolom_baru))`\n"
      ],
      "metadata": {
        "id": "5BUAMh6nmFjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(F.when(df.nilai < 100,\"Low\")\n",
        "    .when(df.nilai < 150,\"Medium\")\n",
        "    .otherwise(\"High\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfIr_LepJdmF",
        "outputId": "ff172023-65f1-4afb-8b48-4d69d6b722da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------+\n",
            "|CASE WHEN (nilai < 100) THEN Low WHEN (nilai < 150) THEN Medium ELSE High END|\n",
            "+-----------------------------------------------------------------------------+\n",
            "|                                                                       Medium|\n",
            "|                                                                         High|\n",
            "|                                                                         High|\n",
            "|                                                                       Medium|\n",
            "|                                                                          Low|\n",
            "|                                                                          Low|\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk menentukan nama kolom yang baru, kita menggunakan fungsi `spark.sql.Column.alias`. Untuk menyertakan kolom-kolom lain digunakan fungsi `spark.sql.functions.cols`"
      ],
      "metadata": {
        "id": "a4KJ4fx6JqUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(F.col(\"*\"), F.when(df.nilai < 100,\"Low\")\n",
        "                    .when(df.nilai < 150,\"Medium\")\n",
        "                    .otherwise(\"High\").alias(\"level\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDxfs9tPlISR",
        "outputId": "b2d9f102-9ad3-4284-8cd6-9345b28400a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+-------+------+\n",
            "| nama|jurusan|nilai|jurusan| level|\n",
            "+-----+-------+-----+-------+------+\n",
            "| Agus| Fisika|  100| Fisika|Medium|\n",
            "|Windy| Fisika|  200| Fisika|  High|\n",
            "| Budi|Biologi|  200|Biologi|  High|\n",
            "| Dina| Fisika|  140| Fisika|Medium|\n",
            "| Bayu| Fisika|   50| Fisika|   Low|\n",
            "| Dedi|Biologi|   50|Biologi|   Low|\n",
            "+-----+-------+-----+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Menambah beberapa kolom baru pada DataFrame dengan select() dan when-otherwise"
      ],
      "metadata": {
        "id": "IpVNSDiRmKxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dengan menggunakan perintah `select`, kita bisa menggunakan beberapa ekspresi when-otherwise untuk membuat beberapa kolom baru sekaligus.\n",
        "\n",
        "Sintaksnya adalah:\n",
        "`df.select(list_kolom, ekspresi1, ekspresi2)`\n"
      ],
      "metadata": {
        "id": "3r7qNrIJmNbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = [['Agus','Fisika',100,180],['Windy','Fisika',200,100],\n",
        "        ['Budi','Biologi',200,150],['Dina','Fisika',140,200],\n",
        "        ['Bayu','Fisika',50,30],['Dedi','Biologi',50,180]]\n",
        "\n",
        "kolom = ['nama','jurusan','nilai1','nilai2']\n",
        "\n",
        "df2 = spark.createDataFrame(data2,kolom)\n",
        "\n",
        "expr1 = F.when(df2.nilai1<150,\"Low\").otherwise(\"High\").alias(\"level1\")\n",
        "expr2 = F.when(df2.nilai2<150,\"Low\").otherwise(\"High\").alias(\"level2\")\n",
        "\n",
        "df2.select(F.col(\"*\"),expr1,expr2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tmHh7kgI54M",
        "outputId": "486adb8f-fa74-4aa0-d3bc-0cc72d2bf528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+------+------+------+------+\n",
            "| nama|jurusan|nilai1|nilai2|level1|level2|\n",
            "+-----+-------+------+------+------+------+\n",
            "| Agus| Fisika|   100|   180|   Low|  High|\n",
            "|Windy| Fisika|   200|   100|  High|   Low|\n",
            "| Budi|Biologi|   200|   150|  High|  High|\n",
            "| Dina| Fisika|   140|   200|   Low|  High|\n",
            "| Bayu| Fisika|    50|    30|   Low|   Low|\n",
            "| Dedi|Biologi|    50|   180|   Low|  High|\n",
            "+-----+-------+------+------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kita juga bisa memilih kolom mana saja yang akan kita sertakan dalam DataFrame yang baru"
      ],
      "metadata": {
        "id": "kx-r_rwW_yDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.select(F.col(\"nama\"),F.col(\"jurusan\"),expr1,expr2).show()"
      ],
      "metadata": {
        "id": "xo1ju1BX0DyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf3464a-02df-4cfd-bba0-83608241237a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+------+------+\n",
            "| nama|jurusan|level1|level2|\n",
            "+-----+-------+------+------+\n",
            "| Agus| Fisika|   Low|  High|\n",
            "|Windy| Fisika|  High|   Low|\n",
            "| Budi|Biologi|  High|  High|\n",
            "| Dina| Fisika|   Low|  High|\n",
            "| Bayu| Fisika|   Low|   Low|\n",
            "| Dedi|Biologi|   Low|  High|\n",
            "+-----+-------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FqSvVXhzj9pu"
      }
    }
  ]
}
