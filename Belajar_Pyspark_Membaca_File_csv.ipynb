{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Belajar Pyspark - Membaca File csv"
      ],
      "metadata": {
        "id": "loueMJbfjlZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam notebook ini kita akan belajar tentang bagaimana membaca file csv ke dalam dataframe, beserta penerapan beberapa parameternya."
      ],
      "metadata": {
        "id": "8fBObxkEIMTP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YsxlynyFZ0N"
      },
      "outputs": [],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F"
      ],
      "metadata": {
        "id": "8V4lQvx6HIiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Belajar PySpark - Membaca file csv\").getOrCreate()"
      ],
      "metadata": {
        "id": "97aBSg6dGu9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Membaca File csv Tanpa Header"
      ],
      "metadata": {
        "id": "KdjOx7p9QucW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/urfie/Seri-Belajar-PySpark/main/dataset/mhs.csv"
      ],
      "metadata": {
        "id": "ShLOQAe3GkEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "File csv tanpa header"
      ],
      "metadata": {
        "id": "iFxsVHKtK205"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat mhs.csv"
      ],
      "metadata": {
        "id": "kd1VKzJVKzSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secara default, spark.read.csv membaca file tanpa header"
      ],
      "metadata": {
        "id": "p5SLu4E6CTx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"mhs.csv\")\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "ZwZ9UhaqoL_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "NX7cxd7lK5lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"csv\").load(\"mhs.csv\")\n",
        "df.show()"
      ],
      "metadata": {
        "id": "sqZBDyuwQISI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Membaca File csv Dengan Header"
      ],
      "metadata": {
        "id": "IGQ5BxFPQ2WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/urfie/Seri-Belajar-PySpark/main/dataset/mhs_header.csv"
      ],
      "metadata": {
        "id": "6qjG2WgDPq-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.read.csv(\"mhs_header.csv\", header=True)\n",
        "df1.printSchema()"
      ],
      "metadata": {
        "id": "SDXiW2n6K7bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "metadata": {
        "id": "j3qI1TpOLEOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.read \\\n",
        "          .option(\"header\",True) \\\n",
        "          .csv(\"mhs_header.csv\")\n",
        "df1.printSchema()"
      ],
      "metadata": {
        "id": "jgDRYgvHtfeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.read \\\n",
        "          .format(\"csv\") \\\n",
        "          .option(\"header\",True) \\\n",
        "          .load(\"mhs_header.csv\")\n",
        "df1.printSchema()"
      ],
      "metadata": {
        "id": "rleh1KkPv1Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Menentukan Tipe Kolom Secara Otomatis"
      ],
      "metadata": {
        "id": "UH3Xkv1mQ5J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = spark.read.csv(\"mhs_header.csv\", header=True, inferSchema=True)\n",
        "df3.show()\n",
        "df3.printSchema()"
      ],
      "metadata": {
        "id": "05A_bKwjP5qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/urfie/Seri-Belajar-PySpark/main/dataset/mhs_notclean.csv"
      ],
      "metadata": {
        "id": "x_4MWMRtP8ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"mhs_notclean.csv\",\n",
        "                    header=True,\n",
        "                    inferSchema=True)\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "291kavIR5neh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\",True) \\\n",
        "      .option(\"inferSchema\",True) \\\n",
        "      .format(\"csv\") \\\n",
        "      .load(\"mhs.csv\")\n",
        "\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "jx_SLXg6QZ2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Membaca File Dengan Delimiter Selain Koma"
      ],
      "metadata": {
        "id": "5ocNXf1NQ9bI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tab delimited file"
      ],
      "metadata": {
        "id": "H514IPmiRHlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/urfie/Seri-Belajar-PySpark/main/dataset/mhs.tsv"
      ],
      "metadata": {
        "id": "SQrwPIG1PyiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = spark.read.csv(\"mhs.tsv\", sep='\\t', header=True, inferSchema=True)\n",
        "df3.printSchema()"
      ],
      "metadata": {
        "id": "naCxAuYMLmXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\",True) \\\n",
        "      .option(\"inferSchema\",True) \\\n",
        "      .option(\"sep\", \"\\t\") \\\n",
        "      .csv(\"mhs.tsv\")\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "z_ELl4xuEf6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mengganti Nilai Tertentu Dengan NULL"
      ],
      "metadata": {
        "id": "Hhoszr9FRMz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"mhs_notclean.csv\",\n",
        "                    header=True,\n",
        "                    inferSchema=True,\n",
        "                    nullValue=\"-\")\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "cTFk031RM0lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tanda Quote Untuk Escape Kolom"
      ],
      "metadata": {
        "id": "wwBOC4YrRQvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/urfie/Seri-Belajar-PySpark/main/dataset/mhs_quote.csv"
      ],
      "metadata": {
        "id": "OvqfYkDtdWbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"mhs_quote.csv\",\n",
        "                    header=True,\n",
        "                    inferSchema=True,\n",
        "                    nullValue=\"-\",\n",
        "                    quote=\"'\")\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "QmViXqlRdjiZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}